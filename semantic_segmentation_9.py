# -*- coding: utf-8 -*-
"""Semantic segmentation_9.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1alP_bVCfO7KtSWsRnd5lV8ix1bgHakZV

<a href="https://colab.research.google.com/github/HARSHGit45/Deep-Learning-Neural-Networks/blob/main/Semantic_Segmentation_UNET.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a>
"""

import os
import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Conv2DTranspose, concatenate
from tensorflow.keras.utils import normalize
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt

# Set paths for images and masks
images_path = r"C:\Users\Anjali\Downloads\semantic segmentation\Images"
masks_path = r"C:\Users\Anjali\Downloads\semantic segmentation\Labels"

# Image dimensions
IMG_HEIGHT = 128
IMG_WIDTH = 128
IMG_CHANNELS = 3

# Load and preprocess data
def load_images_and_masks(images_path, masks_path):
    image_files = sorted(os.listdir(images_path))
    mask_files = sorted(os.listdir(masks_path))

    images = []
    masks = []

    for img_file, mask_file in zip(image_files, mask_files):
        img = tf.keras.preprocessing.image.load_img(os.path.join(images_path, img_file), target_size=(IMG_HEIGHT, IMG_WIDTH))
        mask = tf.keras.preprocessing.image.load_img(os.path.join(masks_path, mask_file), target_size=(IMG_HEIGHT, IMG_WIDTH), color_mode="grayscale")

        img = np.array(img)
        mask = np.array(mask)

        images.append(img)
        masks.append(mask)

    images = np.array(images, dtype=np.float32) / 255.0  # Normalize images
    masks = np.array(masks, dtype=np.float32) / 255.0    # Normalize masks (binary)
    masks = np.expand_dims(masks, axis=-1)               # Add channel dimension to masks

    return images, masks

# Load data
print("Loading data...")
images, masks = load_images_and_masks(images_path, masks_path)
print(f"Images shape: {images.shape}, Masks shape: {masks.shape}")

# Split data into train and validation sets
X_train, X_val, y_train, y_val = train_test_split(images, masks, test_size=0.2, random_state=42)

# Define the U-Net model
def unet_model(input_size=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)):
    inputs = Input(input_size)

    # Encoder
    c1 = Conv2D(16, (3, 3), activation='relu', padding='same')(inputs)
    c1 = Conv2D(16, (3, 3), activation='relu', padding='same')(c1)
    p1 = MaxPooling2D((2, 2))(c1)

    c2 = Conv2D(32, (3, 3), activation='relu', padding='same')(p1)
    c2 = Conv2D(32, (3, 3), activation='relu', padding='same')(c2)
    p2 = MaxPooling2D((2, 2))(c2)

    c3 = Conv2D(64, (3, 3), activation='relu', padding='same')(p2)
    c3 = Conv2D(64, (3, 3), activation='relu', padding='same')(c3)
    p3 = MaxPooling2D((2, 2))(c3)

    # Bottleneck
    c4 = Conv2D(128, (3, 3), activation='relu', padding='same')(p3)
    c4 = Conv2D(128, (3, 3), activation='relu', padding='same')(c4)

    # Decoder
    u5 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c4)
    u5 = concatenate([u5, c3])
    c5 = Conv2D(64, (3, 3), activation='relu', padding='same')(u5)
    c5 = Conv2D(64, (3, 3), activation='relu', padding='same')(c5)

    u6 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c5)
    u6 = concatenate([u6, c2])
    c6 = Conv2D(32, (3, 3), activation='relu', padding='same')(u6)
    c6 = Conv2D(32, (3, 3), activation='relu', padding='same')(c6)

    u7 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(c6)
    u7 = concatenate([u7, c1])
    c7 = Conv2D(16, (3, 3), activation='relu', padding='same')(u7)
    c7 = Conv2D(16, (3, 3), activation='relu', padding='same')(c7)

    outputs = Conv2D(1, (1, 1), activation='sigmoid')(c7)

    model = Model(inputs, outputs)
    return model

# Create model
model = unet_model()
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
model.summary()

# Train the model
print("Training model...")
history = model.fit(
    X_train, y_train,
    validation_data=(X_val, y_val),
    epochs=40,
    batch_size=16
)

# Evaluate the model
print("Evaluating model...")
val_loss, val_accuracy = model.evaluate(X_val, y_val, verbose=0)
print(f"Validation Accuracy: {val_accuracy * 100:.2f}%")

# Visualize training history
plt.figure(figsize=(12, 4))
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('Model Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Model Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()

plt.tight_layout()
plt.show()

# Test on a single image
def test_image(image, model):
    prediction = model.predict(np.expand_dims(image, axis=0))[0]
    return prediction

test_idx = 10  # Example index for testing
test_img = X_val[test_idx]
test_mask = y_val[test_idx]
predicted_mask = test_image(test_img, model)

# Display the results
plt.figure(figsize=(12, 4))
plt.subplot(1, 3, 1)
plt.imshow(test_img)
plt.title("Original Image")

plt.subplot(1, 3, 2)
plt.imshow(test_mask.squeeze(), cmap='gray')
plt.title("True Mask")

plt.subplot(1, 3, 3)
plt.imshow(predicted_mask.squeeze(), cmap='gray')
plt.title("Predicted Mask")

plt.tight_layout()
plt.show()

